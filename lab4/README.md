# Лабораторная работа №4. Линейная регрессия

Целью этой лабораторной работы является реализация линейной регрессии с использованием метода наименьших квадратов.

## Задание
- Студенты с четным порядковым номером в группе должны использовать набор данных о [жилье в Калифорнии] (https://developers.google.com/machine-learning/crash-course/california-housing-data-description?hl=ru). [Скачать тут](https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv).
- Получите и визуализируйте статистику по датасету (включая количество, среднее значение, стандартное отклонение, минимум, максимум и различные квантили).
- Проведите предварительную обработку данных, включая обработку отсутствующих значений, кодирование категориальных признаков и нормировка.
- Разделите данные на обучающий и тестовый наборы данных.
- Реализуйте линейную регрессию с использованием метода наименьших квадратов без использования сторонних библиотек, кроме NumPy и Pandas. Использовать минимизацию суммы квадратов разностей между фактическими и предсказанными значениями для нахождения оптимальных коэффициентов.
- Постройте **три модели** с различными наборами признаков.
- Для каждой модели проведите оценку производительности, используя метрику коэффициент детерминации, чтобы измерить, насколько хорошо модель соответствует данным.
- Сравните результаты трех моделей и сделайте выводы о том, какие признаки работают лучше всего для каждой модели.
- Бонусное задание
    - Ввести синтетический признак при построении модели

## Реализация
Получение статистики реализовано с помощью библиотеки Pandas. Визуализация данных реализована с помощью библиотек Seaborn и matplotlib.pyplot. Кодирование категориальных признаков в данном случае не нужно, нормировка реализована.
Для реализации линейной регресиии был выбран "Матричный метод". Он заключается в нахождении вектора параметров регресии B = (X'X)^(-1)X'Y. Функция нахождения коэффиицента детерминации (R2) также реализована. Был введен синтетический признак в качестве PCA (слияние двух наиболее коррелированных признаков). Были построены модели с различными параметрами (параметры на каждом шаге выбираются рандомно, что позволяет оценить больший спектр моделей). 

### Примеры работы

- Описание датасета:
  
[Link1](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab4/Student_Performance.csv)
[Link2](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab4/california_housing_train.csv)

- Предварительная обработка данных
  
[PCA](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab4/math_lib.py)

- Модели
  
[Matrix](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab4/dima_learns_ml.py)
[Scalar](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab4/dima_learns_ml.py)

### Визуализация данных

[BoxPlot](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab4/main.py)
[Heatmap](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab4/main.py)

## Вывод
В ходе работы я научился анализировать и визуализировать датасет, проводить предварительную обратботку данных, включая обработку отсутствующих значений, кодирование категориальных признаков и нормировку. Также я реализовал методы линейной регрессии средствами языка Python и библиотек NumPy и Pandas. Был введен синтетический признак в качестве PCA (слияние двух наиболее коррелированных признаков). Были построены модели с различными параметрами. 
