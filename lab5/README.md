## Лабораторная 5. Метод k-ближайших соседей

Задание

Выбор датасета:


- Проведите предварительную обработку данных, включая обработку отсутствующих значений, кодирование категориальных признаков и масштабирование.
- Реализуйте метод k-ближайших соседей ****без использования сторонних библиотек, кроме NumPy и Pandas.
- Постройте две модели k-NN с различными наборами признаков:
    - Модель 1: Признаки случайно отбираются .
    - Модель 2: Фиксированный набор признаков, который выбирается заранее.
- Для каждой модели проведите оценку на тестовом наборе данных при разных значениях k. Выберите несколько различных значений k, например, k=3, k=5, k=10, и т. д. Постройте матрицу ошибок.


## Реализация
Получение статистики реализовано с помощью библиотеки Pandas. Визуализация данных реализована с помощью библиотек Seaborn и matplotlib.pyplot. Кодирование категориальных признаков в данном случае не нужно, нормировка реализована.
Решение с использованием станартного метода реализации KNN
### Примеры работы

- Описание датасета:
  
[Link1](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab5/WineDataset.csv)

- Предварительная обработка данных
  
[CROSS validation](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab4/math_lib.py)

- Модель:
  
[K-NN](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab5/dima_learns_ml.py)

- Cross validation:
[GridSearchCV](https://github.com/NorthCapDiamond/Artificial-intelligence-Systems/blob/main/lab5/dima_learns_ml.py)

## Вывод
В ходе работы я научился анализировать и визуализировать датасет, проводить предварительную обратботку данных, включая обработку отсутствующих значений, кодирование категориальных признаков и нормировку. Также я реализовал методы классификации KNN средствами языка Python и библиотек NumPy и Pandas. Были построены модели с различными параметрами. 
